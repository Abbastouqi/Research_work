import gradio as gr
import torch
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import os
import numpy as np

class UrduOptimizedPredictor:
    def __init__(self, model_path=None):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Using device: {self.device}")
        
        # Load the multilingual model
        self.text_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
        self.text_model.to(self.device)
        
        # Load YOUR model
        model_file = "urdu_optimized_model.pkl"
        print(f"ğŸ“ Loading YOUR model from: {model_file}")
        
        try:
            with open(model_file, 'rb') as f:
                model_data = pickle.load(f)
            
            self.emoji_embeddings = {k: v[0] for k, v in model_data['emoji_embeddings'].items()}
            self.emoji_list = model_data['emoji_list']
            
            print(f"âœ… SUCCESS: Loaded YOUR Urdu-optimized model with {len(self.emoji_list)} emojis")
            print(f"ğŸ“Š Your emojis: {self.emoji_list[:20]}...")  # Show first 20 emojis
            
        except Exception as e:
            print(f"âŒ ERROR loading your model: {e}")
            raise e
    
    def predict_smart(self, text, top_k=3, min_confidence=0.3):
        """Use YOUR model for prediction"""
        print(f"\nğŸ” PREDICTING for: '{text}'")
        
        # Get text embedding
        text_embedding = self.text_model.encode([text], convert_to_tensor=True)
        text_embedding_np = text_embedding.cpu().numpy()
        
        # Calculate similarities with YOUR emoji embeddings
        similarities = {}
        for emoji, emoji_embedding in self.emoji_embeddings.items():
            similarity = cosine_similarity(text_embedding_np, emoji_embedding.reshape(1, -1))[0][0]
            similarities[emoji] = similarity
        
        print(f"ğŸ“ˆ Similarities calculated for {len(similarities)} emojis")
        
        # Filter by confidence and return top K
        filtered = [(emoji, score) for emoji, score in similarities.items() if score >= min_confidence]
        sorted_emojis = sorted(filtered, key=lambda x: x[1], reverse=True)
        
        print(f"ğŸ¯ Top predictions: {sorted_emojis[:top_k]}")
        
        # If no confident predictions, return top overall
        if not sorted_emojis:
            top_overall = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]
            print(f"âš ï¸ No confident predictions, using top overall: {top_overall}")
            return top_overall
        
        return sorted_emojis[:top_k]

# Initialize predictor
print("ğŸš€ Loading YOUR Urdu Emoji Prediction Model...")
predictor = UrduOptimizedPredictor()

def predict_emoji(urdu_text):
    """Main prediction function using YOUR model"""
    if not urdu_text.strip():
        return "â¬…ï¸ Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† Ù„Ú©Ú¾ÛŒÚº"
    
    try:
        # Get predictions from YOUR model
        predictions = predictor.predict_smart(urdu_text, top_k=3, min_confidence=0.3)
        
        # Format output - ONLY EMOJIS, no scores or text
        if predictions:
            # Extract just the emojis from predictions
            emojis_only = [emoji for emoji, score in predictions]
            # Join them with spaces for clean display
            result = " ".join(emojis_only)
            return result
        else:
            return "âŒ"
            
    except Exception as e:
        print(f"Error in prediction: {e}")
        return "âš ï¸"

# Test your model with some examples before starting the interface
print("\n" + "="*60)
print("ğŸ§ª TESTING YOUR MODEL WITH SAMPLE TEXTS")
print("="*60)

test_texts = [
    "Ù…ÛŒÚº Ø¨ÛØª Ø®ÙˆØ´ ÛÙˆÚº",
    "Ø¯Ù„ Ù¹ÙˆÙ¹ Ú¯ÛŒØ§ ÛÛ’", 
    "Ø¯ÙˆØ³ØªÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ù¾Ø§Ø±Ù¹ÛŒ Ú©Ø§ Ù…Ø²Û Ø¢ÛŒØ§",
    "Ø§Ù…ÛŒ Ù†Û’ Ù…ÛŒØ±ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÚˆØ´ Ø¨Ù†Ø§Ø¦ÛŒ ÛÛ’",
    "ØºØµÛ Ø³Û’ Ø¯Ù…Ø§Øº Ù¾Ú¾Ù¹ Ø±ÛØ§ ÛÛ’"
]

for text in test_texts:
    print(f"\nğŸ“ Testing: '{text}'")
    predictions = predictor.predict_smart(text, top_k=3, min_confidence=0.3)
    print(f"   â†’ {[emoji for emoji, score in predictions]}")

print("\n" + "="*60)
print("ğŸš€ STARTING GRADIO INTERFACE")
print("="*60)

# Create Gradio interface
demo = gr.Blocks(title="Ø§Ø±Ø¯Ùˆ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù¾ÛŒØ´Ù†Ú¯ÙˆØ¦ÛŒ")

with demo:
    gr.Markdown(
        """
        # ğŸ¯ Ø§Ø±Ø¯Ùˆ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù¾ÛŒØ´Ù†Ú¯ÙˆØ¦ÛŒ
        
        Ø§Ù¾Ù†Û’ Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† Ú©Û’ Ù„ÛŒÛ’ Ù…ÙˆØ²ÙˆÚº ØªØ±ÛŒÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒØ² Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±ÛŒÚº
        
        **10 Ù„Ø§Ú©Ú¾+ Ø§Ø±Ø¯Ùˆ Ù¹ÙˆÛŒÙ¹Ø³** Ù¾Ø± **80+ Ø§Ø±Ø¯Ùˆ Ø§ÛŒÙ…ÙˆØ¬ÛŒØ²** Ø³Û’ ØªØ±Ø¨ÛŒØª ÛŒØ§ÙØªÛ Ù…Ø§ÚˆÙ„
        - **ØªÛŒÙ† Ø¨ÛØªØ±ÛŒÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒØ²** Ú©ÛŒ Ù¾ÛŒØ´Ù†Ú¯ÙˆØ¦ÛŒ
        - ÙÙˆØ±ÛŒ Ø§ÙˆØ± Ø¯Ø±Ø³Øª Ù†ØªØ§Ø¦Ø¬
        - Ù…Ú©Ù…Ù„ Ø·ÙˆØ± Ù¾Ø± Ø§Ø±Ø¯Ùˆ Ú©Û’ Ù„ÛŒÛ’ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©ÛŒØ§ Ú¯ÛŒØ§
        """
    )
    
    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(
                label="Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº",
                placeholder="Ø§Ù¾Ù†Ø§ Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† ÛŒÛØ§Úº Ù„Ú©Ú¾ÛŒÚº... Ù…Ø«Ù„Ø§Ù‹: Ø¢Ø¬ Ù…ÛŒÚº Ø¨ÛØª Ø®ÙˆØ´ ÛÙˆÚº",
                lines=3
            )
            
            predict_btn = gr.Button("ğŸ¯ Ø§ÛŒÙ…ÙˆØ¬ÛŒØ² Ø­Ø§ØµÙ„ Ú©Ø±ÛŒÚº", variant="primary")
            
        with gr.Column():
            output_text = gr.Textbox(
                label="Ù¾ÛŒØ´Ù†Ú¯ÙˆØ¦ÛŒ Ø´Ø¯Û Ø§ÛŒÙ…ÙˆØ¬ÛŒØ²",
                placeholder="ÛŒÛØ§Úº Ø§ÛŒÙ…ÙˆØ¬ÛŒØ² Ø¸Ø§ÛØ± ÛÙˆÚº Ú¯ÛŒ...",
                lines=2
            )
    
    gr.Markdown("### ğŸ’¡ Ù…Ø«Ø§Ù„ÛŒÚº")
    examples = gr.Examples(
        examples=[
            ["Ù…ÛŒÚº Ø¢Ø¬ Ø¨ÛØª Ø®ÙˆØ´ ÛÙˆÚº"],
            ["Ø¯Ù„ Ù¹ÙˆÙ¹ Ú¯ÛŒØ§ ÛÛ’"],
            ["Ø¯ÙˆØ³ØªÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ù¾Ø§Ø±Ù¹ÛŒ Ú©Ø§ Ù…Ø²Û Ø¢ÛŒØ§"],
            ["Ù†ÛŒÙ†Ø¯ Ø¢ Ø±ÛÛŒ ÛÛ’"],
            ["Ø§Ù…ÛŒ Ù†Û’ Ù…ÛŒØ±ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ú©Ú¾Ø§Ù†Ø§ Ø¨Ù†Ø§ÛŒØ§ ÛÛ’"],
            ["Ù…Ø­Ø¨Øª Ù…ÛŒÚº Ù¾Ú‘ Ú¯ÛŒØ§ ÛÙˆÚº"],
            ["ØºØµÛ Ø³Û’ Ø¯Ù…Ø§Øº Ù¾Ú¾Ù¹ Ø±ÛØ§ ÛÛ’"],
            ["Ø¢Ø¬ Ú©Ø§ Ø¯Ù† Ø¨ÛØª Ø®Ø§Øµ ÛÛ’ØŒ Ø³Ø¨ Ø®ÙˆØ´ Ø±ÛÛŒÚº!"]
        ],
        inputs=input_text,
        outputs=output_text,
        fn=predict_emoji,
        cache_examples=False
    )

    # Connect button to function
    predict_btn.click(fn=predict_emoji, inputs=input_text, outputs=output_text)

if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )